{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for distance and h-clustering\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "#Kmeans clustering\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import metrics \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# sklearn does have some functionality too, but mostly a wrapper to scipy\n",
    "from sklearn.metrics import pairwise_distances \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('df_merged.csv')\n",
    "df_ei = pd.read_csv('/Users/maralinetorres/Documents/GitHub/Predicting-Environmental-and-Social-Actions/Datasets/Environmental_impact_cleaned.csv')\n",
    "stocks = pd.read_csv('/Users/maralinetorres/Documents/GitHub/Predicting-Environmental-and-Social-Actions/Datasets/pilot_stocks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = pd.read_csv(\"/Users/maralinetorres/Documents/GitHub/Predicting-Environmental-and-Social-Actions/Datasets/52_tickers_sectors.csv\")\n",
    "stocks['Missing_GHG'] = np.where(stocks['GHG Scope 1'].isna(), 1, 0)\n",
    "df = pd.merge(stocks, sectors, how='inner',on='Ticker')\n",
    "df.drop(columns='Name', inplace=True)\n",
    "stocks = df.copy()\n",
    "stocks['Utility'] = np.where(stocks.Sector == 'Utilities',1,0)\n",
    "stocks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-statistics",
   "metadata": {},
   "source": [
    "## Data Cleaning - version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df = stocks.copy()\n",
    "stocks_df = stocks_df.loc[:, ~stocks_df.columns.isin(['Logarithm_Total_Assets','Logarithm_Total_Sales','Sector','Missing_GHG'])]\n",
    "stocks_df.loc[np.isinf(stocks_df.Annual_Stock_Return),'Annual_Stock_Return'] = np.nan #We can see infinity values for PSX and FANG, we want null values instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute null values with that year industry average\n",
    "null_columns= stocks_df.columns[stocks_df.isnull().any()]\n",
    "null_columns = null_columns.tolist()\n",
    "\n",
    "for column in null_columns:\n",
    "    stocks_df[column] = stocks_df.groupby(['Year','Utility']).transform('mean')[[column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df = stocks_df.loc[:, ~stocks_df.columns.isin(['Annual_Stock_Return','Change_in_TEC'])]\n",
    "stocks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_NaN = stocks_df.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = stocks_df[row_has_NaN]\n",
    "null_columns1= rows_with_NaN.columns[rows_with_NaN.isnull().any()]\n",
    "null_columns1 = null_columns1.tolist()\n",
    "null_columns1.append('Year')\n",
    "rows_with_NaN[null_columns1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_NaN['null_values'] = rows_with_NaN.isnull().sum(axis=1)\n",
    "rows_with_NaN.head()\n",
    "\n",
    "plt.figure(figsize=(10,5));\n",
    "sns.barplot(x='Year', y = 'null_values', data = rows_with_NaN);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get rid of data from 2005 and 2006 because it is missing data for multiple columns\n",
    "stocks_df = stocks_df.loc[stocks_df.Year >= 2007, ]\n",
    "stocks_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-liquid",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering - version 1 and utility industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Standarized the data\n",
    "df = stocks_df[stocks_df.Utility == 1]\n",
    "stock_number = df.select_dtypes('number')\n",
    "sc = StandardScaler()\n",
    "stock_scaled = sc.fit_transform(stock_number)\n",
    "stock_scaled = pd.DataFrame(stock_scaled, columns = stock_number.columns)\n",
    "stock_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Clustering using euclidean and cosine for distance matrix\n",
    "\n",
    "dc1 = pdist(stock_scaled.values) #euclidean\n",
    "dc2 = pdist(stock_scaled.values, metric='cosine')\n",
    "\n",
    "#See now with linkage method and cosine distance matrix work\n",
    "METHODS = ['single', 'complete', 'average', 'ward']\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "for i,m in enumerate(METHODS):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.title(m)\n",
    "    dendrogram(linkage(dc2, method=m),\n",
    "                leaf_rotation= 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 ) See how linkage method and euclidean distance metric work\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "for i,m in enumerate(METHODS):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.title(m)\n",
    "    dendrogram(linkage(dc1, method=m),\n",
    "                leaf_rotation= 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-terror",
   "metadata": {},
   "source": [
    "I am going to use the cosine and average because the cluster start forming lower and there isnt too much height compared to the other methods. Clusters are more group together and compact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Create the labels\n",
    "hc1 = linkage(dc2, method='average')\n",
    "plt.title('Dendogram for Cosine and Average')\n",
    "dendrogram(hc1,\n",
    "            leaf_rotation= 90)\n",
    "plt.axhline(linestyle='--', y=.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = fcluster(hc1, 3, criterion='maxclust')\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the labels into the clean dataset\n",
    "df['cluster'] = labels\n",
    "df.head(3) #Review the dataset with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many stocks per cluster\n",
    "df.cluster.value_counts(dropna=False, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-nation",
   "metadata": {},
   "source": [
    "When using two clusters... we can see that the number of observations are more balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stock_scaled.values\n",
    "sns.scatterplot(X[:,3],X[:,4],hue=df.cluster, cmap=\"rainbow\").set(title='Stock - Hierarchical Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-river",
   "metadata": {},
   "source": [
    "### K-Means Clustering - version 1 and utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster Evaluation - Deciding how many clusters\n",
    "X = stock_scaled.values\n",
    "KRANGE = range(2,10)\n",
    "sse = []\n",
    "\n",
    "## loop over and evaluate\n",
    "for k in KRANGE:\n",
    "  km = KMeans(k)\n",
    "  labs = km.fit_predict(stock_scaled)\n",
    "  sse.append(km.inertia_)\n",
    "\n",
    "#Elbow Method\n",
    "sns.lineplot(KRANGE,sse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing K\n",
    "ss1 = []\n",
    "\n",
    "for k in KRANGE:\n",
    "  km = KMeans(k)\n",
    "  lab = km.fit_predict(stock_scaled)\n",
    "  ss1.append(metrics.silhouette_score(stock_scaled, lab))\n",
    "\n",
    "sns.lineplot(KRANGE, ss1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It shows 3 clusters are the best option... because it radically descreases when 4.\n",
    "\n",
    "##K Means for 3\n",
    "k3 = KMeans(3)\n",
    "k3.fit(X)\n",
    "k3_labs = k3.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['k3'] = k3_labs\n",
    "df.k3.value_counts(dropna=False, sort=False) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-illinois",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering - version 1 and Energy industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Standarized the data\n",
    "df1 = stocks_df[stocks_df.Utility == 0]\n",
    "stock_number = df1.select_dtypes('number')\n",
    "sc = StandardScaler()\n",
    "stock_scaled = sc.fit_transform(stock_number)\n",
    "stock_scaled = pd.DataFrame(stock_scaled, columns = stock_number.columns)\n",
    "stock_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Clustering using euclidean and cosine for distance matrix\n",
    "\n",
    "dc1 = pdist(stock_scaled.values) #euclidean\n",
    "dc2 = pdist(stock_scaled.values, metric='cosine')\n",
    "\n",
    "#See now with linkage method and cosine distance matrix work\n",
    "METHODS = ['single', 'complete', 'average', 'ward']\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "for i,m in enumerate(METHODS):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.title(m)\n",
    "    dendrogram(linkage(dc2, method=m),\n",
    "                leaf_rotation= 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 ) See how linkage method and euclidean distance metric work\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "for i,m in enumerate(METHODS):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.title(m)\n",
    "    dendrogram(linkage(dc1, method=m),\n",
    "                leaf_rotation= 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Create the labels\n",
    "hc1 = linkage(dc2, method='average')\n",
    "plt.title('Dendogram for Cosine and Average')\n",
    "dendrogram(hc1,\n",
    "            leaf_rotation= 90)\n",
    "plt.axhline(linestyle='--', y=.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = fcluster(hc1, 2, criterion='maxclust')\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the labels into the clean dataset\n",
    "df1['cluster'] = labels\n",
    "df1.head(3) #Review the dataset with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many stocks per cluster\n",
    "df1.cluster.value_counts(dropna=False, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-dollar",
   "metadata": {},
   "source": [
    "## K-Means version 1 and energy industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster Evaluation - Deciding how many clusters\n",
    "X = stock_scaled.values\n",
    "KRANGE = range(2,10)\n",
    "sse = []\n",
    "\n",
    "## loop over and evaluate\n",
    "for k in KRANGE:\n",
    "  km = KMeans(k)\n",
    "  labs = km.fit_predict(stock_scaled)\n",
    "  sse.append(km.inertia_)\n",
    "\n",
    "#Elbow Method\n",
    "sns.lineplot(KRANGE,sse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing K\n",
    "ss1 = []\n",
    "\n",
    "for k in KRANGE:\n",
    "  km = KMeans(k)\n",
    "  lab = km.fit_predict(stock_scaled)\n",
    "  ss1.append(metrics.silhouette_score(stock_scaled, lab))\n",
    "\n",
    "sns.lineplot(KRANGE, ss1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It shows 3 clusters are the best option... because it radically descreases when 4.\n",
    "\n",
    "##K Means for 3\n",
    "k3 = KMeans(3)\n",
    "k3.fit(X)\n",
    "k3_labs = k3.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['k3'] = k3_labs\n",
    "df1.k3.value_counts(dropna=False, sort=False) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-composition",
   "metadata": {},
   "source": [
    "## Cluster profiling for Utility industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clus = df.drop(columns=['k3','Utility'])\n",
    "stock_numeric = df_clus.select_dtypes('number')\n",
    "stock_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_profile = stock_numeric.groupby(\"cluster\").mean()\n",
    "clus_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "scp = StandardScaler()\n",
    "cluster_scaled = scp.fit_transform(clus_profile)\n",
    "cluster_scaled = pd.DataFrame(cluster_scaled, index=clus_profile.index, columns=clus_profile.columns)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cluster_scaled.T, cmap=\"Blues\", center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-cloud",
   "metadata": {},
   "source": [
    "## Cluster profiling for Energy industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clus = df1.drop(columns=['cluster','Utility'])\n",
    "stock_numeric = df_clus.select_dtypes('number')\n",
    "stock_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_profile = stock_numeric.groupby(\"k3\").mean()\n",
    "clus_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "scp = StandardScaler()\n",
    "cluster_scaled = scp.fit_transform(clus_profile)\n",
    "cluster_scaled = pd.DataFrame(cluster_scaled, index=clus_profile.index, columns=clus_profile.columns)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cluster_scaled.T, cmap=\"Blues\", center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-setting",
   "metadata": {},
   "source": [
    "## Data Cleaning - version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_clean = stocks.copy()\n",
    "stocks_clean['time_trend'] = stocks_clean.groupby('Ticker').cumcount()\n",
    "stocks_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_clean = stocks_clean.loc[stocks_clean['Missing_GHG'] == 0, stocks_clean.columns.isin(['Company','GHG Scope 1','Total_Assets','Total_Sales','Utility'])]\n",
    "#stocks_clean['Profitable'] = np.where(stocks_clean.Profitable == True, 1, 0)\n",
    "stocks_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = stocks_clean.groupby('Company')[['GHG Scope 1','Total_Assets','Total_Sales']].mean().reset_index()\n",
    "stocks_cleaned = pd.merge(agg, stocks_clean, on='Company', how = 'inner',suffixes=('', '_drop'))\n",
    "stocks_cleaned.drop([col for col in stocks_cleaned.columns if 'drop' in col], axis=1, inplace=True)\n",
    "stocks_cleaned.drop_duplicates(inplace=True)\n",
    "stocks_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-professor",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering - Version 2 and utility industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Standarized the data\n",
    "stocks_clean1 = stocks_cleaned[stocks_cleaned.Utility == 1]\n",
    "stock_number = stocks_clean1.select_dtypes('number')\n",
    "sc = StandardScaler()\n",
    "stock_scaled = sc.fit_transform(stock_number)\n",
    "stock_scaled = pd.DataFrame(stock_scaled, columns = stock_number.columns)\n",
    "stock_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Clustering using euclidean and cosine for distance matrix\n",
    "\n",
    "dc1 = pdist(stock_scaled.values) #euclidean\n",
    "dc2 = pdist(stock_scaled.values, metric='cosine')\n",
    "\n",
    "#See now with linkage method and cosine distance matrix work\n",
    "METHODS = ['single', 'complete', 'average', 'ward']\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "for i,m in enumerate(METHODS):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.title(m)\n",
    "    dendrogram(linkage(dc2, method=m),\n",
    "                leaf_rotation= 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 ) See how linkage method and euclidean distance metric work\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "for i,m in enumerate(METHODS):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.title(m)\n",
    "    dendrogram(linkage(dc1, method=m),\n",
    "                leaf_rotation= 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Create the labels\n",
    "hc1 = linkage(dc2, method='average')\n",
    "plt.title('Dendogram for Cosine and Average')\n",
    "dendrogram(hc1,\n",
    "            leaf_rotation= 90)\n",
    "plt.axhline(linestyle='--', y=.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = fcluster(hc1, 3, criterion='maxclust')\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the labels into the clean dataset\n",
    "stocks_clean1['cluster'] = labels\n",
    "stocks_clean1.head(3) #Review the dataset with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many stocks per cluster\n",
    "stocks_clean1.cluster.value_counts(dropna=False, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-response",
   "metadata": {},
   "source": [
    "## K-Means Clustering - Version 2 and utility industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster Evaluation - Deciding how many clusters\n",
    "X = stock_scaled.values\n",
    "KRANGE = range(2,10)\n",
    "sse = []\n",
    "\n",
    "## loop over and evaluate\n",
    "for k in KRANGE:\n",
    "  km = KMeans(k)\n",
    "  labs = km.fit_predict(stock_scaled)\n",
    "  sse.append(km.inertia_)\n",
    "\n",
    "#Elbow Method\n",
    "sns.lineplot(KRANGE,sse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing K\n",
    "ss1 = []\n",
    "\n",
    "for k in KRANGE:\n",
    "  km = KMeans(k)\n",
    "  lab = km.fit_predict(stock_scaled)\n",
    "  ss1.append(metrics.silhouette_score(stock_scaled, lab))\n",
    "\n",
    "sns.lineplot(KRANGE, ss1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It shows 3 clusters are the best option... because it radically descreases when 4.\n",
    "\n",
    "##K Means for 3\n",
    "k3 = KMeans(3)\n",
    "k3.fit(X)\n",
    "k3_labs = k3.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_clean1['k3'] = k3_labs\n",
    "stocks_clean1.k3.value_counts(dropna=False, sort=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_clean1.to_csv('/Users/maralinetorres/Documents/GitHub/Predicting-Environmental-and-Social-Actions/Datasets/Utility_comp_clustering.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-trial",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering - Version 2 and energy industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Standarized the data\n",
    "stocks_clean2 = stocks_cleaned[stocks_cleaned.Utility == 0]\n",
    "stock_number = stocks_clean2.select_dtypes('number')\n",
    "sc = StandardScaler()\n",
    "stock_scaled = sc.fit_transform(stock_number)\n",
    "stock_scaled = pd.DataFrame(stock_scaled, columns = stock_number.columns)\n",
    "stock_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Clustering using euclidean and cosine for distance matrix\n",
    "\n",
    "dc1 = pdist(stock_scaled.values) #euclidean\n",
    "dc2 = pdist(stock_scaled.values, metric='cosine')\n",
    "\n",
    "#See now with linkage method and cosine distance matrix work\n",
    "METHODS = ['single', 'complete', 'average', 'ward']\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "for i,m in enumerate(METHODS):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.title(m)\n",
    "    dendrogram(linkage(dc2, method=m),\n",
    "                leaf_rotation= 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 ) See how linkage method and euclidean distance metric work\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "for i,m in enumerate(METHODS):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.title(m)\n",
    "    dendrogram(linkage(dc1, method=m),\n",
    "                leaf_rotation= 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Create the labels\n",
    "hc1 = linkage(dc2, method='average')\n",
    "plt.title('Dendogram for Cosine and Average')\n",
    "dendrogram(hc1,\n",
    "            leaf_rotation= 90)\n",
    "plt.axhline(linestyle='--', y=.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = fcluster(hc1, 2, criterion='maxclust')\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the labels into the clean dataset\n",
    "stocks_clean2['cluster'] = labels\n",
    "stocks_clean2.head(3) #Review the dataset with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many stocks per cluster\n",
    "stocks_clean2.cluster.value_counts(dropna=False, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-variance",
   "metadata": {},
   "source": [
    "### K-means Clustering - Version 2 and energy industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster Evaluation - Deciding how many clusters\n",
    "X = stock_scaled.values\n",
    "KRANGE = range(2,10)\n",
    "sse = []\n",
    "\n",
    "## loop over and evaluate\n",
    "for k in KRANGE:\n",
    "  km = KMeans(k)\n",
    "  labs = km.fit_predict(stock_scaled)\n",
    "  sse.append(km.inertia_)\n",
    "\n",
    "#Elbow Method\n",
    "sns.lineplot(KRANGE,sse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing K\n",
    "ss1 = []\n",
    "\n",
    "for k in KRANGE:\n",
    "  km = KMeans(k)\n",
    "  lab = km.fit_predict(stock_scaled)\n",
    "  ss1.append(metrics.silhouette_score(stock_scaled, lab))\n",
    "\n",
    "sns.lineplot(KRANGE, ss1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's go with 4 clusters\n",
    "\n",
    "##K Means for 4\n",
    "k4 = KMeans(3)\n",
    "k4.fit(X)\n",
    "k4_labs = k4.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_clean2['k3'] = k4_labs\n",
    "stocks_clean2.k3.value_counts(dropna=False, sort=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_clean2.to_csv('/Users/maralinetorres/Documents/GitHub/Predicting-Environmental-and-Social-Actions/Datasets/Energy_comp_clustering.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-mission",
   "metadata": {},
   "source": [
    "## Cluster profiling for version 2 and utility industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clus = stocks_clean1.drop(columns=['k3','Utility'])\n",
    "stock_numeric = df_clus.select_dtypes('number')\n",
    "stock_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_profile = stock_numeric.groupby(\"cluster\").mean()\n",
    "clus_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "scp = StandardScaler()\n",
    "cluster_scaled = scp.fit_transform(clus_profile)\n",
    "cluster_scaled = pd.DataFrame(cluster_scaled, index=clus_profile.index, columns=clus_profile.columns)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cluster_scaled.T, cmap=\"Blues\", center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clus1 = stocks_clean1.drop(columns=['cluster','Utility'])\n",
    "stock_numeric = df_clus1.select_dtypes('number')\n",
    "stock_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_profile = stock_numeric.groupby(\"k3\").mean()\n",
    "clus_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "scp = StandardScaler()\n",
    "cluster_scaled = scp.fit_transform(clus_profile)\n",
    "cluster_scaled = pd.DataFrame(cluster_scaled, index=clus_profile.index, columns=clus_profile.columns)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cluster_scaled.T, cmap=\"Blues\", center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-exclusion",
   "metadata": {},
   "source": [
    "## Cluster profiling for version 2 and energy industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clus = stocks_clean2.drop(columns=['k3','Utility'])\n",
    "stock_numeric = df_clus.select_dtypes('number')\n",
    "stock_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_profile = stock_numeric.groupby(\"cluster\").mean()\n",
    "clus_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "scp = StandardScaler()\n",
    "cluster_scaled = scp.fit_transform(clus_profile)\n",
    "cluster_scaled = pd.DataFrame(cluster_scaled, index=clus_profile.index, columns=clus_profile.columns)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cluster_scaled.T, cmap=\"Blues\", center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clus = stocks_clean2.drop(columns=['cluster','Utility'])\n",
    "stock_numeric = df_clus.select_dtypes('number')\n",
    "stock_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_profile = stock_numeric.groupby(\"k3\").mean()\n",
    "clus_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "scp = StandardScaler()\n",
    "cluster_scaled = scp.fit_transform(clus_profile)\n",
    "cluster_scaled = pd.DataFrame(cluster_scaled, index=clus_profile.index, columns=clus_profile.columns)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cluster_scaled.T, cmap=\"Blues\", center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-penny",
   "metadata": {},
   "source": [
    "## Start creating classification score within industry\n",
    "\n",
    "Utility industry\n",
    "- Create new column -> GHG Emissions\n",
    "\t\t○ Cluster 3 --> High\n",
    "\t\t○ Cluster 2 --> Medium\n",
    "\t\t○ Cluster 1 --> Low\n",
    "- Three labels regarding the environmental actions\n",
    "\t\t○ Improving (Or good)\n",
    "\t\t\t§ Last 3 years emissions are below the cluster average\n",
    "\t\t\t§ Last 3 years, the % change in GHG scope is descending\n",
    "\t\t\t§ Last 3 years, the environmental score higher than cluster average\n",
    "\t\t○ Neutral\n",
    "\t\t\tLast 2 years, emissions are below the cluster average\n",
    "\t\t\tLast 2 years, the % change in GHG scope is descending\n",
    "\t\t\tLast 2 years, the environmental score higher than cluster average\n",
    "\t\t○ Deteriorating (Or bad)\n",
    "            Else, then bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_utility = pd.read_csv('/Users/maralinetorres/Documents/GitHub/Predicting-Environmental-and-Social-Actions/Datasets/Utility_comp_clustering.csv')\n",
    "stocks_utility.drop(columns='k3', inplace=True)\n",
    "stocks_utility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_utility_num = stocks_utility.select_dtypes('number')\n",
    "clus_profile = stocks_utility_num.groupby(\"cluster\").mean()\n",
    "clus_profile.sort_values(by='GHG Scope 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ghg = clus_profile['GHG Scope 1'].min()\n",
    "max_ghg = clus_profile['GHG Scope 1'].max()\n",
    "\n",
    "conditions = [ (clus_profile['GHG Scope 1'] == min_ghg),\n",
    "              (clus_profile['GHG Scope 1'] == max_ghg), \n",
    "               (clus_profile['GHG Scope 1'].between(left=min_ghg, right=max_ghg))]\n",
    "choices = ['Low', 'High','Medium']\n",
    "\n",
    "clus_profile['GHG_Emission_category'] = np.select(condlist=conditions, choicelist=choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_profile = clus_profile.sort_values(by='GHG Scope 1').reset_index()\n",
    "clus_profile1 = clus_profile[['cluster','GHG_Emission_category']]\n",
    "clus_profile1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_stocks = pd.merge(stocks_utility, clus_profile1, on='cluster',how = 'inner')\n",
    "cluster_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignEnvironmentalScoreLabel(stocks, companies, cluster_stocks, clus_profile):\n",
    "    companies = cluster_stocks.Company.tolist()\n",
    "    company_label_score = {}\n",
    "    for com in companies:\n",
    "        data = stocks.loc[stocks.Company == com]\n",
    "        clust_num = cluster_stocks.loc[cluster_stocks.Company == com,'cluster'].tolist()\n",
    "        avg_ghg_scope = clus_profile[clus_profile.cluster == clust_num[0]]['GHG Scope 1'].tolist()\n",
    "        year_max = data.Year.max()\n",
    "        year_min = year_max - 2\n",
    "        \n",
    "        assigned = checkMetrics(year_max, year_min, data, 'Improving/Good', company_label_score, com, avg_ghg_scope, companies)\n",
    "        \n",
    "        if assigned == False:\n",
    "            year_min = year_max - 1\n",
    "            data = stocks.loc[stocks.Company == com]\n",
    "            assigned = checkMetrics(year_max, year_min, data, 'Neutral', company_label_score, com, avg_ghg_scope, companies)\n",
    "            if assigned == False:\n",
    "                company_label_score[com] = 'Bad forecast'\n",
    "    return company_label_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkMetrics(maxYear, min_year, data, label, company_label_score, com, avg_ghg_scope, companies):\n",
    "    success = False\n",
    "    com_trend = data.loc[(data.Year <= maxYear) & (data.Year >= min_year), ['Year','Change_in_GHG','Environmental Disclosure Score','GHG Scope 1']]\n",
    "    change_ghg = com_trend['Change_in_GHG'].tolist()\n",
    "    res = all(abs(i) > abs(j) for i, j in zip(change_ghg, change_ghg[1:]))\n",
    "    if res == True:\n",
    "        ghg_scope = com_trend['GHG Scope 1'].tolist()\n",
    "        res_ghg = all(i < avg_ghg_scope[0] for i in ghg_scope)\n",
    "        if res_ghg == True:\n",
    "            eds_list = com_trend['Environmental Disclosure Score'].tolist()\n",
    "            eds = stocks.loc[(stocks.Company.isin(companies))&(stocks.Year <= maxYear) & \n",
    "                             (stocks.Year >= min_year),['Environmental Disclosure Score']].mean().tolist()\n",
    "            res_eds = all(i < eds[0] for i in eds_list)\n",
    "            if res_eds == True:\n",
    "                company_label_score[com] = label\n",
    "                success = True\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = cluster_stocks.Company.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignEnvironmentalScoreLabel(stocks,companies,cluster_stocks, clus_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignEnvironmentalScoreLabel(stocks,['AES CORP (THE)'],cluster_stocks, clus_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-naples",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
